{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils import paths\n",
    "import face_recognition\n",
    "import argparse\n",
    "import pickle\n",
    "import cv2\n",
    "import os\n",
    "from imutils.video import VideoStream\n",
    "import face_recognition\n",
    "import imutils\n",
    "import pickle\n",
    "import time\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Id_number, Name, Contact_no, Permission]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# heading_frame = pd.DataFrame(columns={'a','b','c'})\n",
    "# heading_frame.to_csv(os.path.join('Databse_and_records','main_database_record.csv'),index=False)\n",
    "# print(heading_frame)\n",
    "# os.path.isfile(os.path.join('Database_and_records','main_database_record.csv'\n",
    "# ?pd.DataFrame\n",
    "# heading_frame = pd.DataFrame(columns=['Id_number','Name','Contact_no','Permission'])\n",
    "# print(heading_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path=os.path.join('dataset')\n",
    "encodings_path=os.path.join(\"encodings.pickle\")\n",
    "model='hog'\n",
    "output='video'\n",
    "display=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_paths_finder(data_path):\n",
    "    print(\"[INFO] quantifying faces...\")\n",
    "    imagePaths = list(paths.list_images(data_path))\n",
    "    return imagePaths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_encoder(data_path,encodings_path,model,imagePaths):\n",
    "    knownEncodings = []\n",
    "    knownNames = []\n",
    "\n",
    "            # loop over the image paths\n",
    "    for (i, imagePath) in enumerate(imagePaths):\n",
    "                    # extract the person name from the image path\n",
    "        print(\"[INFO] processing image {}/{}\".format(i + 1,len(imagePaths)))\n",
    "        name = imagePath.split(os.path.sep)[-2]\n",
    "                    \n",
    "\n",
    "                    # load the input image and convert it from RGB (OpenCV ordering)\n",
    "                    # to dlib ordering (RGB)\n",
    "\n",
    "        image = cv2.imread(imagePath)\n",
    "        rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                    # detect the (x, y)-coordinates of the bounding boxes\n",
    "                    # corresponding to each face in the input image\n",
    "        boxes = face_recognition.face_locations(rgb,\n",
    "        model=model)\n",
    "\n",
    "                    # compute the facial embedding for the face\n",
    "        encodings = face_recognition.face_encodings(rgb, boxes)\n",
    "\n",
    "                    # loop over the encodings\n",
    "        for encoding in encodings:\n",
    "                            # add each encoding + name to our set of known names and\n",
    "                           # encodings\n",
    "            knownEncodings.append(encoding)\n",
    "            knownNames.append(name)\n",
    "\n",
    "            # dump the facial encodings + names to disk\n",
    "    print(\"[INFO] serializing encodings...\")\n",
    "    data = {\"encodings\": knownEncodings, \"names\": knownNames}\n",
    "    f = open(encodings_path, \"wb\")\n",
    "    f.write(pickle.dumps(data))\n",
    "    f.close()\n",
    "    image_detector(model,encodings_path,output,display)\n",
    "    return    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_detector(model,encodings,output,display):\n",
    "    count=0\n",
    "    print(\"[INFO] loading encodings...\")\n",
    "    data = pickle.loads(open(encodings, \"rb\").read())\n",
    "    print(\"[INFO] starting video stream...\")\n",
    "    vs = VideoStream(src=0).start()\n",
    "    writer = None\n",
    "    time.sleep(2.0)   \n",
    "    # loop over frames from the video file stream\n",
    "    while True:\n",
    "        # grab the frame from the threaded video stream\n",
    "        frame = vs.read()\n",
    "\n",
    "        # convert the input frame from BGR to RGB then resize it to have\n",
    "        # a width of 750px (to speedup processing)\n",
    "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        rgb = imutils.resize(frame, width=750)\n",
    "        r = frame.shape[1] / float(rgb.shape[1])\n",
    "\n",
    "        # detect the (x, y)-coordinates of the bounding boxes\n",
    "        # corresponding to each face in the input frame, then compute\n",
    "        # the facial embeddings for each face\n",
    "        boxes = face_recognition.face_locations(rgb,model=model)\n",
    "        encodings = face_recognition.face_encodings(rgb, boxes)\n",
    "        names = []\n",
    "        # loop over the facial embeddings\n",
    "        for encoding in encodings:\n",
    "            # attempt to match each face in the input image to our known\n",
    "            # encodings\n",
    "            matches = face_recognition.compare_faces(data[\"encodings\"],encoding)\n",
    "            name = \"Unknown\"\n",
    "\n",
    "            # check to see if we have found a match\n",
    "            if True in matches:\n",
    "                # find the indexes of all matched faces then initialize a\n",
    "                # dictionary to count the total number of times each face\n",
    "                # was matched\n",
    "                matchedIdxs = [i for (i, b) in enumerate(matches) if b]\n",
    "                counts = {}\n",
    "\n",
    "                # loop over the matched indexes and maintain a count for\n",
    "                # each recognized face face\n",
    "                for i in matchedIdxs:\n",
    "                    name = data[\"names\"][i]\n",
    "                    counts[name] = counts.get(name, 0) + 1\n",
    "\n",
    "                # determine the recognized face with the largest number\n",
    "                # of votes (note: in the event of an unlikely tie Python\n",
    "                # will select first entry in the dictionary)\n",
    "                name = max(counts, key=counts.get)\n",
    "\n",
    "            # update the list of names\n",
    "            names.append(name)\n",
    "        \n",
    "        # loop over the recognized faces\n",
    "        for ((top, right, bottom, left), name) in zip(boxes, names):\n",
    "            # rescale the face coordinates\n",
    "            top = int(top * r)\n",
    "            right = int(right * r)\n",
    "            bottom = int(bottom * r)\n",
    "            left = int(left * r)\n",
    "\n",
    "            # draw the predicted face name on the image\n",
    "            cv2.rectangle(frame, (left, top), (right, bottom),\n",
    "                (0, 255, 0), 2)\n",
    "            y = top - 15 if top - 15 > 15 else top + 15\n",
    "            cv2.putText(frame, name, (left, y), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.75, (0, 255, 0), 2)\n",
    "            # Activity on detection of a unknown entry is here\n",
    "            if name == 'Unknown':\n",
    "                count=count+1\n",
    "                if count > 10:\n",
    "                    vs.stop()\n",
    "                    vs.stream.release()\n",
    "                    cv2.destroyAllWindows()\n",
    "                    security_process(frame)   \n",
    "        # if the video writer is None *AND* we are supposed to write\n",
    "        # the output video to disk initialize the writer\n",
    "        if writer is None and output is not None:\n",
    "            fourcc = cv2.VideoWriter_fourcc(*\"MJPG\")\n",
    "            writer = cv2.VideoWriter(output, fourcc, 20,\n",
    "                (frame.shape[1], frame.shape[0]), True)\n",
    "\n",
    "        # if the writer is not None, write the frame with recognized\n",
    "        # faces t odisk\n",
    "        if writer is not None:\n",
    "            writer.write(frame)\n",
    "\n",
    "        # check to see if we are supposed to display the output frame to\n",
    "        # the screen\n",
    "        if display > 0:\n",
    "            cv2.imshow(\"Frame\", frame)\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "            # if the `q` key was pressed, break from the loop\n",
    "            if key == ord(\"q\"):\n",
    "                break\n",
    "\n",
    "    # do a bit of cleanup\n",
    "    cv2.destroyAllWindows()\n",
    "    vs.stop()\n",
    "\n",
    "    # check to see if the video writer point needs to be released\n",
    "    if writer is not None:\n",
    "        writer.release()\n",
    "    return    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def security_process(conflict_image):\n",
    "    cv2.imshow('unknown',conflict_image)\n",
    "    print('what is your name')\n",
    "    name=input()\n",
    "    correct = 'No'\n",
    "    while correct != 'yes':\n",
    "        print(\"Enter your contact number please\")\n",
    "        contact_no = input()\n",
    "        total_no=len(list(contact_no))\n",
    "        list_number=list(contact_no)\n",
    "        alphabets = []\n",
    "        if total_no == 10 :\n",
    "            for word in range(total_no):\n",
    "                if list_number[word].isalpha():\n",
    "                    alphabets.append(list_number[word])\n",
    "            if alphabets == []:\n",
    "                print(\"Thanks for entering valid mobile no\")\n",
    "                correct = 'yes'\n",
    "        else:\n",
    "            print(\"Invalid number entered \")\n",
    "            print(\"enter the number again\")\n",
    "    print('Allow the stranger to come in the premises(y,n):')\n",
    "    permission=input()\n",
    "    cv2.destroyAllWindows()           \n",
    "    if permission == 'n' or permission =='N':\n",
    "        main_database_storge(name,conflict_image,contact_no,\"not Allowed\",\"None\")\n",
    "        print(\"sorry you are not allowed to enter\")\n",
    "    else:\n",
    "        print(\"enter unique Id for the new user\")\n",
    "        Id = input()\n",
    "        main_database_storage(name,conflict_image,contact_no,\"Allowed\",Id)\n",
    "        model_database_maker(name,data_path,Id)\n",
    "    return    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_database_maker(name,dataset_path,Identification_no):\n",
    "    #making new folder in databse\n",
    "    print('please stand on the cross')\n",
    "    os.mkdir(os.path.join(dataset_path,name+str(Identification_no)))\n",
    "    faceDetect = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\");\n",
    "    cam = cv2.VideoCapture(0);\n",
    "    time.sleep(2.0) \n",
    "    sampleNo = 0;\n",
    "    while (sampleNo <= 50):\n",
    "        ret,img = cam.read();\n",
    "        gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY);\n",
    "        faces = faceDetect.detectMultiScale(gray, 1.3, 5);\n",
    "        for(x,y,w,h) in faces:\n",
    "            sampleNo = sampleNo+1;\n",
    "            cv2.imwrite(os.path.join(dataset_path,name+str(Identification_no),name+'.'+str(sampleNo)+'.jpg'),img[y:y+h,x:x+w])\n",
    "            print(dataset_path+'\\\\'+name+str(Identification_no)+'\\\\'+str(name)+\".\"+str(sampleNo)+\".jpg\")\n",
    "            cv2.rectangle(img, (x,y), (x+w,y+h), (0,255,0), 2)\n",
    "            cv2.waitKey(100)\n",
    "        cv2.imshow(\"Face\", img);\n",
    "        cv2.waitKey(1)\n",
    "    cam.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    image_encoder(data_path,encodings_path,model,image_paths_finder(data_path))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_database_storage(name,conflict_image,contact_no,allowance,Identification):\n",
    "    file_exist='No'\n",
    "    while file_exist == 'No':\n",
    "        if os.path.isfile(os.path.join('Database_and_records','main_database_record.csv')):\n",
    "            file_exist = 'yes'\n",
    "            with open(os.path.join('Database_and_records','main_database_record.csv'), 'a', newline='') as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow([Identification,name,contact_no,allowance])\n",
    "                file.close()\n",
    "        else:\n",
    "            heading_frame = pd.DataFrame(columns=['Id_number','Name','Contact_no','Permission'])\n",
    "            heading_frame.to_csv(os.path.join('Database_and_records','main_database_record.csv'),index=True)\n",
    "            file_exist = 'No'\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] quantifying faces...\n",
      "[INFO] serializing encodings...\n",
      "[INFO] loading encodings...\n",
      "[INFO] starting video stream...\n",
      "what is your name\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread WebcamVideoStream:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mansi/.local/lib/python3.6/site-packages/imutils/video/webcamvideostream.py\", line 34, in update\n",
      "    (self.grabbed, self.frame) = self.stream.read()\n",
      "cv2.error: /build/opencv-L2vuMj/opencv-3.2.0+dfsg/modules/core/src/matrix.cpp:943: error: (-5) Unknown array type in function cvarrToMat\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mansi\n",
      "Enter your contact number please\n",
      "1234567890\n",
      "Thanks for entering valid mobile no\n",
      "Allow the stranger to come in the premises(y,n):\n",
      "y\n",
      "enter unique Id for the new user\n",
      "123\n",
      "please stand on the cross\n",
      "dataset\\Mansi123\\Mansi.1.jpg\n",
      "dataset\\Mansi123\\Mansi.2.jpg\n",
      "dataset\\Mansi123\\Mansi.3.jpg\n",
      "dataset\\Mansi123\\Mansi.4.jpg\n",
      "dataset\\Mansi123\\Mansi.5.jpg\n",
      "dataset\\Mansi123\\Mansi.6.jpg\n",
      "dataset\\Mansi123\\Mansi.7.jpg\n",
      "dataset\\Mansi123\\Mansi.8.jpg\n",
      "dataset\\Mansi123\\Mansi.9.jpg\n",
      "dataset\\Mansi123\\Mansi.10.jpg\n",
      "dataset\\Mansi123\\Mansi.11.jpg\n",
      "dataset\\Mansi123\\Mansi.12.jpg\n",
      "dataset\\Mansi123\\Mansi.13.jpg\n",
      "dataset\\Mansi123\\Mansi.14.jpg\n",
      "dataset\\Mansi123\\Mansi.15.jpg\n",
      "dataset\\Mansi123\\Mansi.16.jpg\n",
      "dataset\\Mansi123\\Mansi.17.jpg\n",
      "dataset\\Mansi123\\Mansi.18.jpg\n",
      "dataset\\Mansi123\\Mansi.19.jpg\n",
      "dataset\\Mansi123\\Mansi.20.jpg\n",
      "dataset\\Mansi123\\Mansi.21.jpg\n",
      "dataset\\Mansi123\\Mansi.22.jpg\n",
      "dataset\\Mansi123\\Mansi.23.jpg\n",
      "dataset\\Mansi123\\Mansi.24.jpg\n",
      "dataset\\Mansi123\\Mansi.25.jpg\n",
      "dataset\\Mansi123\\Mansi.26.jpg\n",
      "dataset\\Mansi123\\Mansi.27.jpg\n",
      "dataset\\Mansi123\\Mansi.28.jpg\n",
      "dataset\\Mansi123\\Mansi.29.jpg\n",
      "dataset\\Mansi123\\Mansi.30.jpg\n",
      "dataset\\Mansi123\\Mansi.31.jpg\n",
      "dataset\\Mansi123\\Mansi.32.jpg\n",
      "dataset\\Mansi123\\Mansi.33.jpg\n",
      "dataset\\Mansi123\\Mansi.34.jpg\n",
      "dataset\\Mansi123\\Mansi.35.jpg\n",
      "dataset\\Mansi123\\Mansi.36.jpg\n",
      "dataset\\Mansi123\\Mansi.37.jpg\n",
      "dataset\\Mansi123\\Mansi.38.jpg\n",
      "dataset\\Mansi123\\Mansi.39.jpg\n",
      "dataset\\Mansi123\\Mansi.40.jpg\n",
      "dataset\\Mansi123\\Mansi.41.jpg\n",
      "dataset\\Mansi123\\Mansi.42.jpg\n",
      "dataset\\Mansi123\\Mansi.43.jpg\n",
      "dataset\\Mansi123\\Mansi.44.jpg\n",
      "dataset\\Mansi123\\Mansi.45.jpg\n",
      "dataset\\Mansi123\\Mansi.46.jpg\n",
      "dataset\\Mansi123\\Mansi.47.jpg\n",
      "dataset\\Mansi123\\Mansi.48.jpg\n",
      "dataset\\Mansi123\\Mansi.49.jpg\n",
      "dataset\\Mansi123\\Mansi.50.jpg\n",
      "dataset\\Mansi123\\Mansi.51.jpg\n",
      "[INFO] quantifying faces...\n",
      "[INFO] processing image 1/51\n",
      "[INFO] processing image 2/51\n",
      "[INFO] processing image 3/51\n",
      "[INFO] processing image 4/51\n",
      "[INFO] processing image 5/51\n",
      "[INFO] processing image 6/51\n",
      "[INFO] processing image 7/51\n",
      "[INFO] processing image 8/51\n",
      "[INFO] processing image 9/51\n",
      "[INFO] processing image 10/51\n",
      "[INFO] processing image 11/51\n",
      "[INFO] processing image 12/51\n",
      "[INFO] processing image 13/51\n",
      "[INFO] processing image 14/51\n",
      "[INFO] processing image 15/51\n",
      "[INFO] processing image 16/51\n",
      "[INFO] processing image 17/51\n",
      "[INFO] processing image 18/51\n",
      "[INFO] processing image 19/51\n",
      "[INFO] processing image 20/51\n",
      "[INFO] processing image 21/51\n",
      "[INFO] processing image 22/51\n",
      "[INFO] processing image 23/51\n",
      "[INFO] processing image 24/51\n",
      "[INFO] processing image 25/51\n",
      "[INFO] processing image 26/51\n",
      "[INFO] processing image 27/51\n",
      "[INFO] processing image 28/51\n",
      "[INFO] processing image 29/51\n",
      "[INFO] processing image 30/51\n",
      "[INFO] processing image 31/51\n",
      "[INFO] processing image 32/51\n",
      "[INFO] processing image 33/51\n",
      "[INFO] processing image 34/51\n",
      "[INFO] processing image 35/51\n",
      "[INFO] processing image 36/51\n",
      "[INFO] processing image 37/51\n",
      "[INFO] processing image 38/51\n",
      "[INFO] processing image 39/51\n",
      "[INFO] processing image 40/51\n",
      "[INFO] processing image 41/51\n",
      "[INFO] processing image 42/51\n",
      "[INFO] processing image 43/51\n",
      "[INFO] processing image 44/51\n",
      "[INFO] processing image 45/51\n",
      "[INFO] processing image 46/51\n",
      "[INFO] processing image 47/51\n",
      "[INFO] processing image 48/51\n",
      "[INFO] processing image 49/51\n",
      "[INFO] processing image 50/51\n",
      "[INFO] processing image 51/51\n",
      "[INFO] serializing encodings...\n",
      "[INFO] loading encodings...\n",
      "[INFO] starting video stream...\n"
     ]
    }
   ],
   "source": [
    "image_encoder(data_path,encodings_path,model,image_paths_finder(data_path))\n",
    "image_detector(model,encodings_path,output,display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_storage_unknown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pagal ho gaya mai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hurray !!!!!!!    ab 100% detect hogi tu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dakjdnakldnlakdjadjasdjasdjasdjlakdsjalksdjalkdjakdhakjdhakdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
